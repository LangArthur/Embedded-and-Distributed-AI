{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment2_Transfer_learning.ipynb","private_outputs":true,"provenance":[{"file_id":"https://github.com/LangArthur/Embedded-and-Distributed-AI/blob/master/Assignment2_Transfer-learning/Copy%20of%20Transfer_learning.ipynb","timestamp":1620221322316},{"file_id":"1NCU34kbeW3w4nDZC5Tie5mPrUC1XdRTQ","timestamp":1620213576057}],"collapsed_sections":[],"mount_file_id":"1NCU34kbeW3w4nDZC5Tie5mPrUC1XdRTQ","authorship_tag":"ABX9TyOLN65IWoK+3cvXLuEPkv0Q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ztgmlMKrd9sl"},"source":["#Import necesary libraries\n","import numpy as np\n","import time\n","import pandas as pd\n","import os\n","import cv2\n","import PIL.Image as Image\n","import matplotlib.pylab as plt\n","\n","import tensorflow as tf\n","import tensorflow_hub as hub"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RQvdKJcdmARW"},"source":["#Mount Drive \n","from google.colab import drive\n","drive.mount('/googledrive')\n","\n","# Create a symbolic link to our Google Drive\n","! mkdir -p /googledrive/MyDrive/colabdrive\n","! ln -snf /googledrive/MyDrive/colabdrive/ /colabdrive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G9IOUHcAtn3H"},"source":["!unzip '/googledrive/MyDrive/colabdrive/output'  -d  '/googledrive/MyDrive/colabdrive/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YyDG90OMv0Xg"},"source":["TRAINING_DATASET_PATH=\"/colabdrive/output/train\"\n","TEST_DATASET_PATH=\"/colabdrive/output/test\"\n","VALIDATION_DATASET_PATH=\"/colabdrive/output/val\"\n","EXPORT_PATH='/colabdrive/Saved Model'\n","TFLITE_EXPORT_PATH=EXPORT_PATH+\"/model.tflite\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ijViOwSVdjOE"},"source":["batch_size = 32 # Set batch size\n","img_height = 224 #Set image height \n","img_width = 224 #Set image width\n","\n","#Creatin test, train and validation set, set the image dimensions and the batch size\n","trainSet = tf.keras.preprocessing.image_dataset_from_directory(\n","  str(TRAINING_DATASET_PATH),\n","  seed=123,\n","  image_size=(img_height, img_width),\n","  batch_size=batch_size)\n","\n","testSet = tf.keras.preprocessing.image_dataset_from_directory(\n","  str(TEST_DATASET_PATH),\n","  seed=123,\n","  image_size=(img_height, img_width),\n","  batch_size=batch_size)\n","\n","validationSet = tf.keras.preprocessing.image_dataset_from_directory(\n","  str(VALIDATION_DATASET_PATH),\n","  seed=123,\n","  image_size=(img_height, img_width),\n","  batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_QfArGVZd49b"},"source":["#Retrieve class names and the number of classes\n","classNames = np.array(validationSet.class_names)\n","numberOfClasses = len(classNames)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f1dLYG_D2Okj"},"source":["# Function for Rescaling and setiing the buffer size for datasets\n","def dataProcessing(dataset):\n","  normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n","  dataset = dataset.map(lambda x, y: (normalization_layer(x), y))\n","  AUTOTUNE = tf.data.AUTOTUNE\n","  dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)\n","  return dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b_bCC5hzd8sv"},"source":["#Rescaling of images from datasets\n","trainSet = dataProcessing(trainSet)\n","testSet = dataProcessing(testSet)\n","validationSet = dataProcessing(validationSet)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hElwTmtwekA9"},"source":["#IF YOU RUN THE FOLLOWING CELLS, YOU WILL TRAIN A MODEL. YOU HAVE THE OPTION TO LOAD AN ALREADY TRAINED MODEL AND SAVE TIME BY RUNNING THE CELL (LOAD THE TRAINED MODEL)\n","# Seting the feature extractor layer using a pre-treined headless layer from TensorFlow Hub\n","feature_extractor_layer = hub.KerasLayer(\n","    \"https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/5\", input_shape=(224, 224, 3), trainable=False)\n","\n","#Creating a Sequential model using the feature extractor layer and a top layer for classification of traffic signs\n","model = tf.keras.Sequential([\n","  feature_extractor_layer,\n","  tf.keras.layers.Dense(numberOfClasses)\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x6Q-FnOug7ay"},"source":["#Summary of the model\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dJ1f9P5DjNK_"},"source":["model.compile(\n","  optimizer=tf.keras.optimizers.Adam(),\n","  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","  metrics=['acc'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b4OHEPrdjWfO"},"source":["#Custom callback to log the loss and accuracy of each batch individually, instead of the epoch average.\n","class CollectBatchStats(tf.keras.callbacks.Callback):\n","  def __init__(self):\n","    self.batch_losses = []\n","    self.batch_acc = []\n","\n","  def on_train_batch_end(self, batch, logs=None):\n","    self.batch_losses.append(logs['loss'])\n","    self.batch_acc.append(logs['acc'])\n","    self.model.reset_metrics()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pnPTmn9RjaJ5"},"source":["#Model training with the evaluation of each batch\n","batchStatsCallback = CollectBatchStats()\n","\n","history = model.fit(trainSet, epochs=4,validation_data = validationSet,\n","                    callbacks=[batchStatsCallback])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yG5O3jrMOiFB"},"source":["#Evaluation of the model\n","score = model.evaluate(testSet, verbose=0)\n","print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OZb71ALblG4o"},"source":["t = time.time()\n","\n","export_path = EXPORT_PATH+\"/{}\".format(int(t))\n","model.save(export_path)\n","\n","export_path"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1cWDJhKRll7L"},"source":["#LOAD THE TRAINED MODEL\n","\n","#Reload the saved model\n","\n","reloadedModel = tf.keras.models.load_model(export_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZRdS1Wcw-b8b"},"source":["#Visualisation of model predictions for the first batch of images\n","for imageBatch,_ in testSet:\n","  break\n","\n","reloadedResultBatch= reloadedModel.predict(imageBatch)\n","predictedId = np.argmax(reloadedResultBatch, axis=-1)\n","predicteLlabelBatch = classNames[predictedId]\n","plt.figure(figsize=(10,9))\n","plt.subplots_adjust(hspace=0.5)\n","for n in range(30):\n","  plt.subplot(6,5,n+1)\n","  plt.imshow(imageBatch[n])\n","  plt.title(predicteLlabelBatch[n].title())\n","  plt.axis('off')\n","_ = plt.suptitle(\"Model predictions\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4P4QfU0tl-DM"},"source":["\n","PredictionsOnTestSet = reloadedModel.predict(testSet)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RQIjrRPTc9MD"},"source":["#Convert the model into a TF Lite model and saving it on drive\n","converter = tf.lite.TFLiteConverter.from_saved_model(export_path) # path to the SavedModel directory\n","tfliteModel = converter.convert()\n","with open(EXPORT_PATH+\"/model.tflite\", 'wb') as f:\n","  f.write(tfliteModel)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DYr-LyhQdd5N"},"source":["#Load the TF Lite model \n","tfliteInterpreter = tf.lite.Interpreter(TFLITE_EXPORT_PATH)\n","inputDetails = tfliteInterpreter.get_input_details() #Get input details\n","outputDetails = tfliteInterpreter.get_output_details() #Get output details\n","tfliteInterpreter.resize_tensor_input(inputDetails[0]['index'], (1, 224, 224, 3)) #Resize the input for making prediction on an image\n","tfliteInterpreter.resize_tensor_input(outputDetails[0]['index'], (1, len(classNames)))\n","tfliteInterpreter.allocate_tensors()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yYDIybwSnYXq"},"source":["\n","testImage=Image.open(TEST_DATASET_PATH+'/20/00000_00000_00027.png').resize((224,224)) #Lite model predictions on an image\n","testImage=np.array(testImage,  dtype=np.float32)/255.0\n","testImage.shape\n","Img = testImage[np.newaxis, ...]\n","startTime = time.time()\n","result = tfliteInterpreter.set_tensor(inputDetails[0]['index'],Img)\n","tfliteInterpreter.invoke()\n","tfliteModelPredictions = tfliteInterpreter.get_tensor(outputDetails[0]['index'])\n","endTime = time.time()\n","predictedClass = np.argmax(tfliteModelPredictions[0], axis=-1)\n","predictedClassName = classNames[predictedClass]\n","duration = endTime - startTime\n","print(f\"Prediction time for an image: {duration} seconds\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kY1AJOVIszDM"},"source":["#TF Lite  model predictions on an image\n","\n","plt.figure(figsize=(10,9))\n","plt.subplots_adjust(hspace=0.5)\n","plt.imshow(testImage)\n","plt.title(predictedClassName.title())\n","plt.axis('off')\n","_ = plt.suptitle(\"Model predictions for an image\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gFrEpSN5GmpM"},"source":[" # Accuracy of the lite model on test dataset\n","\n","def load_dataset(directory): \n","    \"\"\"\n","    Returns: \n","    X_orig -- np.array containing all images\n","    y_orig -- np.array containing all image labels\n","    \"\"\"\n","\n","    y_orig = [] # store class number\n","    X_orig = []\n","\n","    for category in os.listdir(directory):\n","        flower_path = os.path.join(directory, category)\n","        for file_name in os.listdir(flower_path):\n","            img = cv2.cvtColor(cv2.imread(os.path.join(flower_path, file_name)), cv2.COLOR_BGR2RGB)\n","            if img is not None :\n","                resized=cv2.resize(img,(224,224))/255.0\n","                X_orig.append(resized)            \n","                y_orig.append(category)\n","    \n","    y_orig = np.array(y_orig)\n","    # y_orig = y_orig.reshape((1, y_orig.shape[0]))\n","        \n","    return X_orig, y_orig\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9am5Q53eHbhW"},"source":["X, y = load_dataset(TEST_DATASET_PATH)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"akPhDIfOJ7mm"},"source":["predictedLabels=list()\n","\n","for i in range(len(X)):\n","  startTimeAverage=time.time()\n","  Img = X[i][np.newaxis, ...]\n","  Img=np.array(Img,  dtype=np.float32)\n","  result = tfliteInterpreter.set_tensor(inputDetails[0]['index'],Img)\n","  tfliteInterpreter.invoke()\n","  tfliteModelPredictions = tfliteInterpreter.get_tensor(outputDetails[0]['index'])\n","  endTimeAverage = time.time()\n","  predictedClass = np.argmax(tfliteModelPredictions[0], axis=-1)\n","  predictedClassName = classNames[predictedClass]\n","  predictedLabels.append(predictedClassName)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LFin7Iv01swA"},"source":["averageTimePerImage=(endTimeAverage-startTimeAverage)/len(predictedLabels)\n","print(\"Average time for making one prediction: \",averageTimePerImage )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AbFwdkby4_XP"},"source":["def compute_accuracy(realLabels, predictedLabels):\n","  correctPredictions=0\n","  for i in range(len(realLabels)):\n","    if realLabels[i]==predictedLabels[i]:\n","      correctPredictions+=1\n","  accuracy=correctPredictions/len(realLabels)*100\n","  return accuracy\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ta2wPfPhLhO8"},"source":["print(\"Lite model accuracy: \",compute_accuracy(y,predictedLabels))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MsNS36lMLoL3"},"source":[""],"execution_count":null,"outputs":[]}]}